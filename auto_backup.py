#!/usr/bin/env python3
"""
è‡ªåŠ¨å¤‡ä»½è„šæœ¬ - å®šæœŸå¤‡ä»½Taskså’ŒDiscoveriesæ•°æ®
ä½¿ç”¨æ–¹æ³•:
1. å®šæ—¶å¤‡ä»½: python auto_backup.py --schedule
2. ç«‹å³å¤‡ä»½: python auto_backup.py --backup
3. æŸ¥çœ‹ç»Ÿè®¡: python auto_backup.py --stats
"""

import schedule
import time
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
import requests
import sys

# é…ç½®
SERVER_URL = "http://localhost:5000"
DATA_DIR = Path(__file__).parent / "data"
BACKUP_DIR = DATA_DIR / "backups"
LOG_FILE = DATA_DIR / "backup.log"

def log_message(message):
    """è®°å½•æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}\n"
    print(log_entry.strip())
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    LOG_FILE.parent.mkdir(exist_ok=True)
    
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(log_entry)

def create_backup():
    """åˆ›å»ºå¤‡ä»½"""
    try:
        response = requests.post(f"{SERVER_URL}/backup", timeout=10)
        if response.status_code == 200:
            data = response.json()
            log_message(f"âœ… å¤‡ä»½æˆåŠŸ: {data.get('filename', 'unknown')}")
            return True
        else:
            log_message(f"âŒ å¤‡ä»½å¤±è´¥: HTTP {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        log_message("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
        return False
    except Exception as e:
        log_message(f"âŒ å¤‡ä»½å‡ºé”™: {str(e)}")
        return False

def get_stats():
    """è·å–æ•°æ®ç»Ÿè®¡"""
    try:
        response = requests.get(f"{SERVER_URL}/api/stats", timeout=10)
        if response.status_code == 200:
            return response.json()
        return None
    except:
        return None

def cleanup_old_backups(days=30):
    """æ¸…ç†è€çš„å¤‡ä»½æ–‡ä»¶"""
    if not BACKUP_DIR.exists():
        return
    
    cutoff_date = datetime.now() - timedelta(days=days)
    cleaned_count = 0
    
    for backup_file in BACKUP_DIR.glob("backup_*.json"):
        try:
            # ä»æ–‡ä»¶åæå–æ—¥æœŸ
            timestamp_str = backup_file.stem.replace("backup_", "")
            file_date = datetime.strptime(timestamp_str.split("_")[0], "%Y%m%d")
            
            if file_date < cutoff_date:
                backup_file.unlink()
                cleaned_count += 1
        except:
            continue
    
    if cleaned_count > 0:
        log_message(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} ä¸ªè¶…è¿‡ {days} å¤©çš„å¤‡ä»½æ–‡ä»¶")

def show_stats():
    """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
    stats = get_stats()
    if stats:
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»ä»»åŠ¡æ•°: {stats['total_tasks']}")
        print(f"   å·²å®Œæˆä»»åŠ¡: {stats['completed_tasks']}")
        print(f"   å¾…åŠä»»åŠ¡: {stats['pending_tasks']}")
        print(f"   å‘ç°æ€»æ•°: {stats['total_discoveries']}")
        print(f"   æœ€åæ›´æ–°: {stats['last_updated']}")
        
        # æ˜¾ç¤ºå¤‡ä»½æ–‡ä»¶æ•°é‡
        if BACKUP_DIR.exists():
            backup_count = len(list(BACKUP_DIR.glob("backup_*.json")))
            print(f"   å¤‡ä»½æ–‡ä»¶æ•°: {backup_count}")
    else:
        print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")

def backup_job():
    """å®šæ—¶å¤‡ä»½ä»»åŠ¡"""
    log_message("ğŸ• å¼€å§‹æ‰§è¡Œå®šæ—¶å¤‡ä»½...")
    
    # åˆ›å»ºå¤‡ä»½
    if create_backup():
        # æ¸…ç†è€å¤‡ä»½æ–‡ä»¶
        cleanup_old_backups(30)
        log_message("âœ… å®šæ—¶å¤‡ä»½å®Œæˆ")
    else:
        log_message("âŒ å®šæ—¶å¤‡ä»½å¤±è´¥")

def start_scheduler():
    """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
    log_message("ğŸš€ å¯åŠ¨è‡ªåŠ¨å¤‡ä»½æœåŠ¡...")
    
    # æ¯å°æ—¶å¤‡ä»½ä¸€æ¬¡
    schedule.every().hour.do(backup_job)
    
    # æ¯å¤©å‡Œæ™¨2ç‚¹æ¸…ç†è€æ–‡ä»¶
    schedule.every().day.at("02:00").do(lambda: cleanup_old_backups(30))
    
    log_message("â° å®šæ—¶ä»»åŠ¡å·²è®¾ç½®:")
    log_message("   - æ¯å°æ—¶è‡ªåŠ¨å¤‡ä»½")
    log_message("   - æ¯å¤©å‡Œæ™¨2ç‚¹æ¸…ç†30å¤©å‰çš„å¤‡ä»½")
    log_message("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        log_message("ğŸ“´ è‡ªåŠ¨å¤‡ä»½æœåŠ¡å·²åœæ­¢")

def main():
    parser = argparse.ArgumentParser(description="Tasks & Discoveries è‡ªåŠ¨å¤‡ä»½å·¥å…·")
    parser.add_argument("--schedule", action="store_true", help="å¯åŠ¨å®šæ—¶å¤‡ä»½æœåŠ¡")
    parser.add_argument("--backup", action="store_true", help="ç«‹å³æ‰§è¡Œå¤‡ä»½")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡")
    parser.add_argument("--cleanup", type=int, metavar="DAYS", help="æ¸…ç†Nå¤©å‰çš„å¤‡ä»½æ–‡ä»¶")
    
    args = parser.parse_args()
    
    if args.schedule:
        start_scheduler()
    elif args.backup:
        print("ğŸ”„ æ­£åœ¨åˆ›å»ºå¤‡ä»½...")
        if create_backup():
            print("âœ… å¤‡ä»½å®Œæˆ")
        else:
            print("âŒ å¤‡ä»½å¤±è´¥")
            sys.exit(1)
    elif args.stats:
        show_stats()
    elif args.cleanup:
        print(f"ğŸ§¹ æ¸…ç† {args.cleanup} å¤©å‰çš„å¤‡ä»½æ–‡ä»¶...")
        cleanup_old_backups(args.cleanup)
        print("âœ… æ¸…ç†å®Œæˆ")
    else:
        parser.print_help()
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
        print("   python auto_backup.py --backup     # ç«‹å³å¤‡ä»½")
        print("   python auto_backup.py --schedule   # å¯åŠ¨å®šæ—¶å¤‡ä»½")
        print("   python auto_backup.py --stats      # æŸ¥çœ‹ç»Ÿè®¡")

if __name__ == "__main__":
    main() 